import base64
from typing import Dict, List, Optional, Any, Union
from functools import wraps

import openai
import anthropic

from config import OPENAI_API_KEY, ANTHROPIC_API_KEY, GPT_MODEL, MAX_TOKENS
from bot.utils.logger import setup_logger


# ================================================
# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏–π
# ================================================
IMAGE_ANALYSIS_PROMPT = "–û–ø–∏—à–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:"
ERROR_ANTHROPIC_KEY_MISSING = "–û—à–∏–±–∫–∞: API –∫–ª—é—á Anthropic –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"
ERROR_OPERATION_FAILED = "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –æ–ø–µ—Ä–∞—Ü–∏–∏"

# ================================================
# –õ–æ–≥–≥–µ—Ä –¥–ª—è —Å–µ—Ä–≤–∏—Å–∞ –ò–ò
# ================================================
logger = setup_logger(__name__)




def error_handler(func):
    # –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è —É–Ω–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
    @wraps(func)
    async def wrapper(*args, **kwargs):
        try:
            result = await func(*args, **kwargs)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –ø—É—Å—Ç–æ–π
            if not result or not str(result).strip():
                logger.warning("üö® –ü–£–°–¢–û–ô –û–¢–í–ï–¢ –û–¢ –ù–ï–ô–†–û–°–ï–¢–ò:")
                logger.warning(f"   –¢–∏–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {type(result)}")
                logger.warning(f"   –ó–Ω–∞—á–µ–Ω–∏–µ: {repr(result)}")
                logger.warning(f"   –î–ª–∏–Ω–∞: {len(str(result)) if result else 0}")
                logger.warning(f"   –§—É–Ω–∫—Ü–∏—è: {func.__name__}")
                return "–ù–µ–π—Ä–æ—Å–µ—Ç—å –≤–µ—Ä–Ω—É–ª–∞ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
            return result
        except Exception as e:
            return f"{ERROR_OPERATION_FAILED}: {str(e)}"
    return wrapper


class AIService:
    
    def __init__(self, model_name: str = None):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏ –ò–ò —á–µ—Ä–µ–∑ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ API
        # model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ None, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è GPT_MODEL –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏)
        self.model_name = model_name or GPT_MODEL
        
        # ================================================
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤
        # ================================================
        self.openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)
        self.anthropic_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY) if ANTHROPIC_API_KEY else None
    
    def is_claude_model(self) -> bool:
        # –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å Claude
        return self.model_name and "claude" in self.model_name.lower()
    
    def _prepare_messages(
        self, content: Union[str, List[Dict]], context: List[Dict[str, str]] = None, 
        system_prompt: str = None
    ) -> List[Dict[str, str]]:
        # –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        if context is None:
            context = []
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ—Ç –ø—É—Å—Ç—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        filtered_context = []
        for msg in context:
            if msg.get("content") and str(msg["content"]).strip():
                filtered_context.append(msg)
            
        user_message = {"role": "user", "content": content}
        messages = filtered_context + [user_message]
        
        if system_prompt and system_prompt.strip():
            messages.insert(0, {"role": "system", "content": system_prompt.strip()})
        
        return messages
    
    @error_handler
    async def _make_api_call(
        self, messages: List[Dict[str, str]], system_prompt: str = None
    ) -> str:
        # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è API –≤—ã–∑–æ–≤–æ–≤ –∫ –ª—é–±–æ–º—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä—É
        logger.info(f"üì§ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:")
        logger.info(f"   –ú–æ–¥–µ–ª—å: {self.model_name}")
        logger.info(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {len(messages)}")
        
        # –î–ª—è Claude –ª–æ–≥–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –æ—Ç–¥–µ–ª—å–Ω–æ, –¥–ª—è OpenAI –æ–Ω —É–∂–µ –≤ messages
        if self.is_claude_model():
            logger.debug(f"   –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (Claude): {repr(system_prompt)}")
        
        for i, msg in enumerate(messages):
            logger.debug(f"   –°–æ–æ–±—â–µ–Ω–∏–µ {i+1}: {msg['role']} -> {repr(msg['content'][:100])}{'...' if len(str(msg['content'])) > 100 else ''}")
        
        if self.is_claude_model():
            if not self.anthropic_client:
                return ERROR_ANTHROPIC_KEY_MISSING
            
            # –£–±–∏—Ä–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è Claude
            claude_messages = [msg for msg in messages if msg["role"] != "system"]
            
            response = self.anthropic_client.messages.create(
                model=self.model_name,
                max_tokens=MAX_TOKENS,
                messages=claude_messages,
                system=system_prompt or ""
            )
            result = response.content[0].text
            logger.info(f"ü§ñ Claude API –æ—Ç–≤–µ—Ç:")
            logger.debug(f"   –ú–æ–¥–µ–ª—å: {self.model_name}")
            logger.debug(f"   –¢–∏–ø response.content: {type(response.content)}")
            logger.debug(f"   –î–ª–∏–Ω–∞ content: {len(response.content)}")
            logger.debug(f"   –ü–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç: {repr(response.content[0]) if response.content else 'None'}")
            logger.debug(f"   –¢–µ–∫—Å—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {repr(result)}")
            logger.debug(f"   –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(result) if result else 0}")
            return result
        else:
            # OpenAI
            params = {
                "model": self.model_name,
                "messages": messages,
                "max_completion_tokens": MAX_TOKENS
            }
            
            response = self.openai_client.chat.completions.create(**params)
            result = response.choices[0].message.content
            finish_reason = response.choices[0].finish_reason
            
            logger.info(f"ü§ñ OpenAI API –æ—Ç–≤–µ—Ç:")
            logger.debug(f"   –ú–æ–¥–µ–ª—å: {self.model_name}")
            logger.debug(f"   Finish reason: {finish_reason}")
            logger.debug(f"   –¢–∏–ø choices: {type(response.choices)}")
            logger.debug(f"   –î–ª–∏–Ω–∞ choices: {len(response.choices)}")
            logger.debug(f"   –ü–µ—Ä–≤—ã–π choice: {repr(response.choices[0]) if response.choices else 'None'}")
            logger.debug(f"   –¢–µ–∫—Å—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {repr(result)}")
            logger.debug(f"   –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(result) if result else 0}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏—á–∏–Ω—É –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            if finish_reason == 'length':
                return f"‚ö†Ô∏è –û—Ç–≤–µ—Ç –±—ã–ª –æ–±—Ä–µ–∑–∞–Ω –∏–∑-–∑–∞ –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–¥–∞—Ç—å –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –æ—á–∏—Å—Ç–∏—Ç–µ –∏—Å—Ç–æ—Ä–∏—é –∫–æ–º–∞–Ω–¥–æ–π /reset."
            
            return result
    
    async def get_response(
        self, message: str, context: List[Dict[str, str]] = None, system_prompt: str = None
    ) -> str:
        # –ü–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –ò–ò —á–µ—Ä–µ–∑ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ API
        # message: –¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–π –±–µ—Å–µ–¥—ã
        # system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –º–æ–¥–µ–ª–∏
        messages = self._prepare_messages(message, context, system_prompt)
        # –î–ª—è Claude –ø–µ—Ä–µ–¥–∞–µ–º system_prompt –æ—Ç–¥–µ–ª—å–Ω–æ, –¥–ª—è OpenAI –æ–Ω —É–∂–µ –≤ messages
        claude_system_prompt = system_prompt if self.is_claude_model() else None
        return await self._make_api_call(messages, claude_system_prompt)
    
    def _create_image_content(self, encoded_image: str) -> List[Dict]:
        # –°–æ–∑–¥–∞–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç —Å–æ–æ–±—â–µ–Ω–∏—è —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –¥–ª—è —Ä–∞–∑–Ω—ã—Ö API
        if self.is_claude_model():
            return [{
                "type": "text",
                "text": IMAGE_ANALYSIS_PROMPT
            }, {
                "type": "image",
                "source": {
                    "type": "base64",
                    "media_type": "image/jpeg",
                    "data": encoded_image
                }
            }]
        else:
            return [{
                "type": "text", 
                "text": IMAGE_ANALYSIS_PROMPT
            }, {
                "type": "image_url",
                "image_url": {"url": f"data:image/jpeg;base64,{encoded_image}"}
            }]
    
    @error_handler
    async def read_image(self, image_path: str) -> str:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ API
        # image_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        with open(image_path, "rb") as image_file:
            encoded_image = base64.b64encode(image_file.read()).decode("utf-8")
        
        image_content = self._create_image_content(encoded_image)
        messages = self._prepare_messages(image_content)
        return await self._make_api_call(messages)